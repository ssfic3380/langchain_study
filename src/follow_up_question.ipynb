{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "심화 질문\n",
    "\n",
    "심화 질문의 조건\n",
    "- 지식 질문인 경우: 이 사람이 “핵심”을 알고 있는지 확인해야 함\n",
    "- 경험 질문인 경우: 이 사람이 “실제로” 그 일을 했는지를 확인해야 함\n",
    "\n",
    "핵심을 알고 있는지 어떻게 판단할 것인가?\n",
    "- 면접관이 던진 질문에 대한 답변을 한 것인지 확인해야 함\n",
    "- 만약 그 지식에서 핵심적인 부분이 빠졌다면 그 부분을 캐물어야 함\n",
    "\n",
    "실제로 그 일을 했는지 어떻게 판단할 것인가?\n",
    "- 경험을 얘기했는데, 구체적인 설명이 없을 때: 좀 더 자세히 설명하도록 한 뒤, 그 경험에 대해서 면접관은 궁금한 내용을 물어본다.\n",
    "- 경험에 대해서 구체적으로 설명했을 때: 그 경험에 대해서 궁금한 내용을 물어본다.\n",
    "- 궁금한 내용은 무엇인가?: 직무와 관련된 경험이라면 어떤 역할을 하고 뭘 배웠는지, 협업과 관련된 내용이라면 어떤 기여를 했고 뭘 배웠는지\n",
    "    - 만약 혼자 일 하는 업종이라면.. 그런 직업이 뭐가 있지?\n",
    "\n",
    "\n",
    "기타 고민\n",
    "\n",
    "면접자가 필살기를 던졌을 때, 그것을 어떻게 캐치 할 것인가?\n",
    "- 그 사람이 무엇을 말하고 싶어하는지 핵심을 알아내야 함\n",
    "- 굳이 필살기를 분류하려 할 필요 없이, 우리는 면접자가 경험을 언급한다면 그 경험을 통해서 얻은 것을 파악하고, 직무에 도움이 되는 경험인지 판단하면 된다.\n",
    "    - 그 판단은 위의 2가지임\n",
    "\n",
    "GPT가 평가해줘야 할 것들\n",
    "- 면접관의 질문의 의도에 맞는 답변을 했는가?\n",
    "    - 프롬프트를 짤 때 “~한지 판단해라. 그리고 ~하지 않다면 그것에 대해서 질문해라.” 이렇게 쓸 텐데, “~한지 판단해라” 부분을 평가로 따로 빼서 피드백 페이지에서 보여주면 좋을 듯\n",
    "- 내가 언급한 경험에서 나온 질문에 대해서 잘 답변을 했는가? (면접 전에 당연히 준비 해야 하는 거니까)\n",
    "- 질문에 대해서 단답을 하지 않고 경험과 엮어서 잘 이야기 했는가?\n",
    "- 성장 하기 위해 무언가를 했는가? 노력하는 방법을 알고 있는가? (성장 가능성에 대한 어필 = 신입인 경우)\n",
    "\n",
    "결론: 프롬프트를 짤 때 면접관의 입장에서 면접자에 대해서 궁금한 것이 무엇일지 생각해보자\n",
    "- 직무에 대한 지식이 있는가?\n",
    "- 이 사람이 직무와 관련된 경험이 있고, 실제로 그 일을 해 봤는가?\n",
    "- 성장 가능성이 있는가?(신입)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Langchain\n",
    "\n",
    "Module 종류\n",
    "- Model I/O: 언어 모델을 이용하기 위한 인터페이스\n",
    "- Data connection: 애플리케이션에 특화된 데이터를 이용하기 위한 인터페이스\n",
    "- Chains: Call의 순서를 구축하기 위한 모듈\n",
    "- Agents: 주어진 고수준의 지시를 처리하기 위해 어떤 tool을 사용해야 할지 chain이 선택할 수 있도록 해주는 모듈\n",
    "- Memory: chain이 상태를 유지할 수 있도록 해주는 모듈\n",
    "- Callbacks: chain의 중간 단계의 로그를 남기고 스트리밍 하기 위한 모듈\n",
    "\n",
    "Model I/O\n",
    "- Prompts: 템플릿화를 통해 모델의 input을 동적으로 선택하고 관리\n",
    "- Language models: 공통 인터페이스를 통해 언어 모델을 호출\n",
    "- Output parses: 모델의 output에서 정보를 추출\n",
    "\n",
    "Prompts\n",
    "- Prompt templates: 모델의 input을 파라미터화\n",
    "- Example selectors: prompt에 포함할 예제를 동적으로 선택\n",
    "\n",
    "Prompt templates\n",
    "- Connecting to a Feature Store: 데이터를 최신 상태로 관리하는 Feature Store와 연결하고 싶을 때 참고\n",
    "- Custom prompt template: LLM에 대한 복잡한 동작을 지시하기 위해 나만의 prompt template을 만드는 방법\n",
    "- Few-shot prompt templates: 적은 수의 예제를 이용해서 prompt template을 구성하는 방법\n",
    "- Few shot examples for chat models: Few-shot 예제를 Chat Model에서 활용해보기\n",
    "- Format template output:\n",
    "    - format 메소드: 사용자의 입력을 prompt에 넣는 메소드. 출력하면 그 결과를 볼 수 있음\n",
    "    - format_prompt 메소드: format을 수행한 뒤, prompt를 ChatPromptValue 형으로 변환시키는 메소드\n",
    "- Template formats: template을 prompt로 변환할 때(PromptTemplate.from_template()), PromptTemplate는 template을 파이썬의 f-string으로 취급하는데, template_format 인자를 추가해줌으로써 다른 format으로 취급하도록 변경할 수 있다.\n",
    "- Types of MessagePromptTemplate: MessagePromptTemplate의 종류에 대해서 설명 (ChatMessagePromptTemplate, AIMessagePromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../config.env')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T19:16:30.258709200Z",
     "start_time": "2023-07-01T19:16:30.253708100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from handler.custom_streaming_handler import CustomStreamingCallbackHandler\n",
    "\n",
    "from langchain.schema import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    SystemMessage\n",
    ")\n",
    "\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    AIMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "chat = ChatOpenAI(streaming=True,\n",
    "                  callbacks=[CustomStreamingCallbackHandler()],\n",
    "                  temperature=0.5,\n",
    "                  verbose=True)\n",
    "\n",
    "#chat.predict_messages([HumanMessage(content=\"Translate this sentence from English to Korean. I love programming.\")])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T19:16:31.402599300Z",
     "start_time": "2023-07-01T19:16:31.394597500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "llm = OpenAI(temperature=0.5)\n",
    "\n",
    "info_template = \"\"\"\n",
    "너는 회사의 신입 사원을 뽑는 면접관이다.\n",
    "먼저 회사와 직무에 대한 정보는 다음과 같다.\n",
    "\n",
    "[\n",
    "회사명: {company}\n",
    "직무명: {job}\n",
    "모집 공고: {job_requirements}\n",
    "]\n",
    "\n",
    "\n",
    "위 정보를 이용하여 회사가 원하는 신입은 어떤 사람인지 분석하라.\n",
    "\"\"\"\n",
    "info_prompt = PromptTemplate(\n",
    "    input_variables=[\"company\", \"job\", \"job_requirements\"],\n",
    "    template=info_template\n",
    ")\n",
    "\n",
    "info_chain = LLMChain(llm=llm,\n",
    "                      prompt=info_prompt,\n",
    "                      output_key=\"info_analysis\"\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T20:14:02.210518200Z",
     "start_time": "2023-07-01T20:14:02.195515600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [],
   "source": [
    "cover_letter_template = \"\"\"\n",
    "앞서 분석했던 회사의 정보는 다음과 같다.\n",
    "\n",
    "[\n",
    "{info_analysis}\n",
    "]\n",
    "\n",
    "\n",
    "다음으로 주어지는 정보는 면접에 응시하는 면접자의 자기소개서이다.\n",
    "\n",
    "[\n",
    "{cover_letter}\n",
    "]\n",
    "\n",
    "\n",
    "이 자기소개서를 분석하여 좋은 점과 부족한 점을 3가지씩 분석해라.\n",
    "답변은 아래의 형식을 따라서 출력하라.\n",
    "\n",
    "잘한 점:\n",
    " - 잘한 내용들\n",
    "\n",
    "부족한 점:\n",
    " - 부족한 내용들\n",
    "\"\"\"\n",
    "\n",
    "cover_letter_prompt = PromptTemplate(\n",
    "    input_variables=[\"info_analysis\",\n",
    "                     \"cover_letter\"],\n",
    "    template=cover_letter_template\n",
    ")\n",
    "\n",
    "cover_letter_chain = LLMChain(llm=llm,\n",
    "                              prompt=cover_letter_prompt,\n",
    "                              output_key=\"cover_letter_analysis\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T20:14:39.546670800Z",
     "start_time": "2023-07-01T20:14:39.540669Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(chains=[info_chain, cover_letter_chain],\n",
    "                                input_variables=[\"company\", \"job\", \"job_requirements\",\n",
    "                                                 \"cover_letter\"],\n",
    "                                output_variables=[\"info_analysis\",\n",
    "                                                  \"cover_letter_analysis\"],\n",
    "                                verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T20:15:29.280443200Z",
     "start_time": "2023-07-01T20:15:29.266439700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new  chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "{'company': 'LG CNS', 'job': 'DX Engineer', 'job_requirements': '\\n전사: DX Engineer\\n전공: 전공 무관 (*) 단, 컴퓨터공학/정보통신공학/산업공학/전자전기공학/기계공학 등 이공계열은 우대합니다\\n근무지: 서울특별시\\n인원: 00명\\n상세내용:\\n- 이런 일을 해요\\n  - 다양한 산업 분야에서 DX 신기술로 고객 맞춤형 서비스를 제공하며, 고객 비즈니스에 가치를 더하는 일을 합니다\\n  - 기존에 없던 새로운 시스템을 만들어내고, 시스템을 안정적으로 운영해냅니다.\\n  - 디지털금융, 지능형 정부, 스마트시티, 스마트 교통 서비스 등 편리하고 보다 나은 삶을 위한 변화를 이끌어갑니다.\\n  - 국내외 고객에게 DX환경에 적합한 클라우드 인프라 설계/구축/컨설팅/운영 서비스를 제공합니다.\\n  - 국내 및 해외(미국, 유럽, 중국 등) 데이터센터와 클라우드 인프라 기술을 이용하여, 전 세계를 하나로 연결하는 서비스를 제공합니다.\\n\\n- 이런 분이면 더 좋겠어요!\\n  - 새로운 시도를 즐기고, IT를 통해 세상의 변화를 이끌어가고 싶은 분\\n  - 끊임없이 신기술을 익히고 적용하며 성장하고 싶으신 분\\n  - 비즈니스를 이해하고 더 편리한 서비스를 제공하는데 관심이 많으신 분\\n', 'cover_letter': '\\n1. LG CNS에서 근무하고 싶은 이유에 대해서 관련된 경험 및 역량 등 자신을 어필할 수 있는 내용을 기반으로 자유롭게 기술하시기 바랍니다.\\n답변:\\n저는 기술적 도전을 통해 기대를 뛰어넘는 결과를 만들어서 사용자에게 더욱 편리한 서비스를 제공하는 개발자가 되고 싶습니다. LG CNS는 최초로 자바를 개발언어로 사용하는 도전을 통해 고객의 니즈를 바탕으로 더욱 뛰어난 결과를 만들어낸 경험이 있고,카카오뱅크 전산시스템을 통해 인터넷 은행의 시대를 열었습니다. 또한 현재 AI,클라우드,IoT,블록체인 등 4차산업기술을 선도하고 있고, 그 중에서도 특히 클라우드 전환과 MSP 사업에 앞서고 가장 많은 AM프로젝트를 수행하는 등 클라우드 기술을 기반으로 디지털 혁신에 앞장서고 있습니다.\\n\\n저는 프로젝트를 진행하며 요구사항을 직접 세우고 분석하는 과정을 통해 애플리케이션 설계,데이터 모델링,백엔드 등에 대한 지식을 갖출 수 있었고, 앱,웹,AI모델링과 같은 다양한 기술에 도전하면서 새로운 기술에 대한 적응력을 얻었습니다. 이러한 경험과 LG CNS의 혁신 정신을 바탕으로 신기술을 배우고 활용하여 고객에게 최고의 서비스를 제공하고자 합니다.\\n\\n', 'info_analysis': '\\nLG CNS의 DX Engineer로서 회사가 원하는 신입은 새로운 시도를 즐기고, IT를 통해 세상의 변화를 이끌어가고 싶은 분, 끊임없이 신기술을 익히고 적용하며 성장하고 싶으신 분, 비즈니스를 이해하고 더 편리한 서비스를 제공하는데 관심이', 'cover_letter_analysis': '\\n잘한 점:\\n - LG CNS의 혁신정신과 관련된 경험을 가지고 있음\\n - 애플리케이션 설계, 데이터 모델링, 백엔드 등에 대한 지식을 갖춤\\n - 다양한 기술에 도전하며 새로운 기술에 대한 적응력을 얻음\\n\\n부족한 점:\\n - 명확한 목표를 밝혀'}\n"
     ]
    }
   ],
   "source": [
    "input_company = \"LG CNS\"\n",
    "input_job = \"DX Engineer\"\n",
    "\n",
    "input_job_requirements = \"\"\"\n",
    "전사: DX Engineer\n",
    "전공: 전공 무관 (*) 단, 컴퓨터공학/정보통신공학/산업공학/전자전기공학/기계공학 등 이공계열은 우대합니다\n",
    "근무지: 서울특별시\n",
    "인원: 00명\n",
    "상세내용:\n",
    "- 이런 일을 해요\n",
    "  - 다양한 산업 분야에서 DX 신기술로 고객 맞춤형 서비스를 제공하며, 고객 비즈니스에 가치를 더하는 일을 합니다\n",
    "  - 기존에 없던 새로운 시스템을 만들어내고, 시스템을 안정적으로 운영해냅니다.\n",
    "  - 디지털금융, 지능형 정부, 스마트시티, 스마트 교통 서비스 등 편리하고 보다 나은 삶을 위한 변화를 이끌어갑니다.\n",
    "  - 국내외 고객에게 DX환경에 적합한 클라우드 인프라 설계/구축/컨설팅/운영 서비스를 제공합니다.\n",
    "  - 국내 및 해외(미국, 유럽, 중국 등) 데이터센터와 클라우드 인프라 기술을 이용하여, 전 세계를 하나로 연결하는 서비스를 제공합니다.\n",
    "\n",
    "- 이런 분이면 더 좋겠어요!\n",
    "  - 새로운 시도를 즐기고, IT를 통해 세상의 변화를 이끌어가고 싶은 분\n",
    "  - 끊임없이 신기술을 익히고 적용하며 성장하고 싶으신 분\n",
    "  - 비즈니스를 이해하고 더 편리한 서비스를 제공하는데 관심이 많으신 분\n",
    "\"\"\"\n",
    "\n",
    "input_cover_letter = \"\"\"\n",
    "1. LG CNS에서 근무하고 싶은 이유에 대해서 관련된 경험 및 역량 등 자신을 어필할 수 있는 내용을 기반으로 자유롭게 기술하시기 바랍니다.\n",
    "답변:\n",
    "저는 기술적 도전을 통해 기대를 뛰어넘는 결과를 만들어서 사용자에게 더욱 편리한 서비스를 제공하는 개발자가 되고 싶습니다. LG CNS는 최초로 자바를 개발언어로 사용하는 도전을 통해 고객의 니즈를 바탕으로 더욱 뛰어난 결과를 만들어낸 경험이 있고,카카오뱅크 전산시스템을 통해 인터넷 은행의 시대를 열었습니다. 또한 현재 AI,클라우드,IoT,블록체인 등 4차산업기술을 선도하고 있고, 그 중에서도 특히 클라우드 전환과 MSP 사업에 앞서고 가장 많은 AM프로젝트를 수행하는 등 클라우드 기술을 기반으로 디지털 혁신에 앞장서고 있습니다.\n",
    "\n",
    "저는 프로젝트를 진행하며 요구사항을 직접 세우고 분석하는 과정을 통해 애플리케이션 설계,데이터 모델링,백엔드 등에 대한 지식을 갖출 수 있었고, 앱,웹,AI모델링과 같은 다양한 기술에 도전하면서 새로운 기술에 대한 적응력을 얻었습니다. 이러한 경험과 LG CNS의 혁신 정신을 바탕으로 신기술을 배우고 활용하여 고객에게 최고의 서비스를 제공하고자 합니다.\n",
    "\n",
    "2. 지원분야와 관련된 지식이나 경험을 기재하여 주십시오.\n",
    "답변:\n",
    "\"식사 추천 앱\"\n",
    "사용자의 식습관을 토대로 음식을 추천해주는 안드로이드 앱 프로젝트로, 설문 조사를 통해 약 200여 건의 식사 기록을 확보하고 AWS의 SaaS형태의 학습 서비스를 이용하여 학습 한 뒤, AWS 클라우드 서비스를 기반으로 서버를 구축한 서비스입니다. 저는 AWS 서비스와 API를 통해 통신하며 앱에서 음식 추천 목록과 선택된 음식의 정보를 띄워주고, 게시판 및 댓글 기능을 지원하는 등 앱의 기능을 구현하는 역할을 담당했습니다.\n",
    "\n",
    "이 프로젝트를 진행하면서 사용자의 시점에서 직접 요구 사항을 작성하고, 개발자의 시점에서 요구사항을 만족하기 위해 필요한 기술과 리스크를 예측해볼 수 있었습니다. 또한 API를 통한 서버와의 통신 시 주고 받아야 할 요청 사항과 응답 내용에 대한 협의 과정을 겪을 수 있었고, 짧은 시간 내에 프로젝트에 적용하기 위해서 안드로이드 docs를 찾아가며 지식을 습득하고 적용했던 과정을 통해서 새로운 지식 습득에 대한 자신감을 가질 수 있었습니다.\n",
    "\n",
    "\n",
    "3. 10년 뒤 본인이 기대하는 모습을 기재하여 주십시오.\n",
    "답변:\n",
    "지금의 DX는 단순히 종이 신문을 스마트폰으로 보여주고, 쇼핑몰을 인터넷으로 옮기는 것이 아니라 4차 산업 기술을 인프라나 시스템에 적용하고 서비스와 결합하고 있습니다. 하지만 4차 산업 기술들은 이제야 제대로 된 발전 과정에 들어섰을 뿐, 진짜 변화는 지금부터라고 생각합니다. 그 중에서도 클라우드 분야는 앞으로는 개인 컴퓨터 없이 모니터와 마우스만 가지고 컴퓨팅 자원을 빌려서 사용하는 시대가 올 정도로 발전하게 될 것이라고 생각합니다.\n",
    "\n",
    "이런 미래를 앞두고 있는 상황에서 저는 클라우드 기반의 인프라 지식 또한 DX 엔지니어로써 갖추어야 할 소양이라고 생각합니다. 저는 다양한 프로젝트에 참여하여 경험을 쌓으면서 다양한 분야의 업무와 시스템 구조를 파악하며 각 산업에 대한 지식을 갖추고, 동시에 지속적인 자기 계발을 통해 개발 기술과 함께 클라우드 지식까지 갖춘 전문가가 되어 고객의 기대를 뛰어넘는 DX 경험을 제공하는 최고의 인재가 되겠습니다.\n",
    "\"\"\"\n",
    "\n",
    "print(overall_chain({\n",
    "    'company': input_company,\n",
    "    'job': input_job,\n",
    "    'job_requirements': input_job_requirements,\n",
    "    'cover_letter': input_cover_letter\n",
    "}))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T20:25:07.155943500Z",
     "start_time": "2023-07-01T20:24:31.075715900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "data": {
      "text/plain": "SequentialChain(memory=None, callbacks=None, callback_manager=None, verbose=True, tags=None, chains=[LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, prompt=PromptTemplate(input_variables=['company', 'job', 'job_requirements'], output_parser=None, partial_variables={}, template='\\n너는 회사의 신입 사원을 뽑는 면접관이다.\\n먼저 회사와 직무에 대한 정보는 다음과 같다.\\n\\n[\\n회사명: {company}\\n직무명: {job}\\n모집 공고: {job_requirements}\\n]\\n\\n\\n위 정보를 이용하여 회사가 원하는 신입은 어떤 사람인지 분석하라.\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.5, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all', tiktoken_model_name=None), output_key='info_analysis', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={}), LLMChain(memory=None, callbacks=None, callback_manager=None, verbose=False, tags=None, prompt=PromptTemplate(input_variables=['info_analysis', 'cover_letter'], output_parser=None, partial_variables={}, template='\\n앞서 분석했던 회사의 정보는 다음과 같다.\\n\\n[\\n{info_analysis}\\n]\\n\\n\\n다음으로 주어지는 정보는 면접에 응시하는 면접자의 자기소개서이다.\\n\\n[\\n{cover_letter}\\n]\\n\\n\\n이 자기소개서를 분석하여 좋은 점과 부족한 점을 3가지씩 분석해라.\\n답변은 아래의 형식을 따라서 출력하라.\\n\\n잘한 점:\\n - 잘한 내용들\\n\\n부족한 점:\\n - 부족한 내용들\\n', template_format='f-string', validate_template=True), llm=OpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, client=<class 'openai.api_resources.completion.Completion'>, model_name='text-davinci-003', temperature=0.5, max_tokens=256, top_p=1, frequency_penalty=0, presence_penalty=0, n=1, best_of=1, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', batch_size=20, request_timeout=None, logit_bias={}, max_retries=6, streaming=False, allowed_special=set(), disallowed_special='all', tiktoken_model_name=None), output_key='cover_letter_analysis', output_parser=NoOpOutputParser(), return_final_only=True, llm_kwargs={})], input_variables=['company', 'job', 'job_requirements', 'cover_letter'], output_variables=['info_analysis', 'cover_letter_analysis'], return_all=False)"
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.width', sys.maxsize)\n",
    "overall_chain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T20:42:44.405905Z",
     "start_time": "2023-07-01T20:42:44.095835Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'text'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 38\u001B[0m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# 4. chat prompt에 입력을 넣어서 결과를 받는다.\u001B[39;00m\n\u001B[0;32m     20\u001B[0m input_job_requirements \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;124m전사: DX Engineer\u001B[39m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;124m전공: 전공 무관 (*) 단, 컴퓨터공학/정보통신공학/산업공학/전자전기공학/기계공학 등 이공계열은 우대합니다\u001B[39m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;124m  - 비즈니스를 이해하고 더 편리한 서비스를 제공하는데 관심이 많으신 분\u001B[39m\n\u001B[0;32m     37\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m---> 38\u001B[0m \u001B[43minitial_chat_prompt\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mformat_messages\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcompany\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mLG CNS\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjob\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mDX Engineer\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mjob_requirements\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minput_job_requirements\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     40\u001B[0m \u001B[38;5;66;03m# 5. Chain으로 2개를 엮어서 결과값을 출력하기\u001B[39;00m\n\u001B[0;32m     41\u001B[0m chain \u001B[38;5;241m=\u001B[39m LLMChain(llm\u001B[38;5;241m=\u001B[39mchat, prompt\u001B[38;5;241m=\u001B[39minitial_chat_prompt)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\langchain\\lib\\site-packages\\langchain\\prompts\\chat.py:237\u001B[0m, in \u001B[0;36mChatPromptTemplate.format_messages\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    231\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(message_template, BaseMessagePromptTemplate):\n\u001B[0;32m    232\u001B[0m     rel_params \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m    233\u001B[0m         k: v\n\u001B[0;32m    234\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m k, v \u001B[38;5;129;01min\u001B[39;00m kwargs\u001B[38;5;241m.\u001B[39mitems()\n\u001B[0;32m    235\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m message_template\u001B[38;5;241m.\u001B[39minput_variables\n\u001B[0;32m    236\u001B[0m     }\n\u001B[1;32m--> 237\u001B[0m     message \u001B[38;5;241m=\u001B[39m message_template\u001B[38;5;241m.\u001B[39mformat_messages(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mrel_params)\n\u001B[0;32m    238\u001B[0m     result\u001B[38;5;241m.\u001B[39mextend(message)\n\u001B[0;32m    239\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\langchain\\lib\\site-packages\\langchain\\prompts\\chat.py:100\u001B[0m, in \u001B[0;36mBaseStringMessagePromptTemplate.format_messages\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat_messages\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m List[BaseMessage]:\n\u001B[1;32m--> 100\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)]\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\langchain\\lib\\site-packages\\langchain\\prompts\\chat.py:119\u001B[0m, in \u001B[0;36mHumanMessagePromptTemplate.format\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseMessage:\n\u001B[1;32m--> 119\u001B[0m     text \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mprompt\u001B[38;5;241m.\u001B[39mformat(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    120\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m HumanMessage(content\u001B[38;5;241m=\u001B[39mtext, additional_kwargs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39madditional_kwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\langchain\\lib\\site-packages\\langchain\\prompts\\prompt.py:67\u001B[0m, in \u001B[0;36mPromptTemplate.format\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m     52\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Format the prompt with the inputs.\u001B[39;00m\n\u001B[0;32m     53\u001B[0m \n\u001B[0;32m     54\u001B[0m \u001B[38;5;124;03mArgs:\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     64\u001B[0m \u001B[38;5;124;03m    prompt.format(variable1=\"foo\")\u001B[39;00m\n\u001B[0;32m     65\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     66\u001B[0m kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_merge_partial_and_user_variables(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m---> 67\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m DEFAULT_FORMATTER_MAPPING[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtemplate_format](\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtemplate, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\langchain\\lib\\string.py:161\u001B[0m, in \u001B[0;36mFormatter.format\u001B[1;34m(self, format_string, *args, **kwargs)\u001B[0m\n\u001B[0;32m    160\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mformat\u001B[39m(\u001B[38;5;28mself\u001B[39m, format_string, \u001B[38;5;241m/\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m--> 161\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformat_string\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\langchain\\lib\\site-packages\\langchain\\formatting.py:29\u001B[0m, in \u001B[0;36mStrictFormatter.vformat\u001B[1;34m(self, format_string, args, kwargs)\u001B[0m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m     25\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m     26\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNo arguments should be provided, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     27\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124meverything should be passed as keyword arguments.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     28\u001B[0m     )\n\u001B[1;32m---> 29\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformat_string\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\langchain\\lib\\string.py:165\u001B[0m, in \u001B[0;36mFormatter.vformat\u001B[1;34m(self, format_string, args, kwargs)\u001B[0m\n\u001B[0;32m    163\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mvformat\u001B[39m(\u001B[38;5;28mself\u001B[39m, format_string, args, kwargs):\n\u001B[0;32m    164\u001B[0m     used_args \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n\u001B[1;32m--> 165\u001B[0m     result, _ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_vformat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mformat_string\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mused_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m    166\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcheck_unused_args(used_args, args, kwargs)\n\u001B[0;32m    167\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\langchain\\lib\\string.py:205\u001B[0m, in \u001B[0;36mFormatter._vformat\u001B[1;34m(self, format_string, args, kwargs, used_args, recursion_depth, auto_arg_index)\u001B[0m\n\u001B[0;32m    201\u001B[0m     auto_arg_index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m    203\u001B[0m \u001B[38;5;66;03m# given the field_name, find the object it references\u001B[39;00m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;66;03m#  and the argument it came from\u001B[39;00m\n\u001B[1;32m--> 205\u001B[0m obj, arg_used \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_field\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfield_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    206\u001B[0m used_args\u001B[38;5;241m.\u001B[39madd(arg_used)\n\u001B[0;32m    208\u001B[0m \u001B[38;5;66;03m# do any conversion on the resulting object\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\langchain\\lib\\string.py:270\u001B[0m, in \u001B[0;36mFormatter.get_field\u001B[1;34m(self, field_name, args, kwargs)\u001B[0m\n\u001B[0;32m    267\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_field\u001B[39m(\u001B[38;5;28mself\u001B[39m, field_name, args, kwargs):\n\u001B[0;32m    268\u001B[0m     first, rest \u001B[38;5;241m=\u001B[39m _string\u001B[38;5;241m.\u001B[39mformatter_field_name_split(field_name)\n\u001B[1;32m--> 270\u001B[0m     obj \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_value\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfirst\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    272\u001B[0m     \u001B[38;5;66;03m# loop through the rest of the field_name, doing\u001B[39;00m\n\u001B[0;32m    273\u001B[0m     \u001B[38;5;66;03m#  getattr or getitem as needed\u001B[39;00m\n\u001B[0;32m    274\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m is_attr, i \u001B[38;5;129;01min\u001B[39;00m rest:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\langchain\\lib\\string.py:227\u001B[0m, in \u001B[0;36mFormatter.get_value\u001B[1;34m(self, key, args, kwargs)\u001B[0m\n\u001B[0;32m    225\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m args[key]\n\u001B[0;32m    226\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 227\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mkwargs\u001B[49m\u001B[43m[\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m]\u001B[49m\n",
      "\u001B[1;31mKeyError\u001B[0m: 'text'"
     ]
    }
   ],
   "source": [
    "# 1. template를 만들고, system message prompt로 변환한다.\n",
    "initial_system_message_template = \"\"\"\n",
    "너는 회사의 신입 면접자를 뽑는 면접관이다.\n",
    "회사와 직군의 정보는 다음과 같다.\n",
    "\n",
    "회사명: {company}\n",
    "직무명: {job}\n",
    "모집 공고: {job_requirements}\n",
    "\"\"\"\n",
    "initial_system_message_prompt = SystemMessagePromptTemplate.from_template(initial_system_message_template)\n",
    "\n",
    "# 2. human_template를 만들고, human message prompt로 변환한다.\n",
    "user_input_template = \"{text}\"\n",
    "user_input_prompt = HumanMessagePromptTemplate.from_template(user_input_template)\n",
    "\n",
    "# 3. system message prompt와 human message prompt를 이용해서 chat prompt를 만든다.\n",
    "initial_chat_prompt = ChatPromptTemplate.from_messages([initial_system_message_prompt, user_input_prompt])\n",
    "\n",
    "# 4. chat prompt에 입력을 넣어서 결과를 받는다.\n",
    "input_job_requirements = \"\"\"\n",
    "전사: DX Engineer\n",
    "전공: 전공 무관 (*) 단, 컴퓨터공학/정보통신공학/산업공학/전자전기공학/기계공학 등 이공계열은 우대합니다\n",
    "근무지: 서울특별시\n",
    "인원: 00명\n",
    "상세내용:\n",
    "- 이런 일을 해요\n",
    "  - 다양한 산업 분야에서 DX 신기술로 고객 맞춤형 서비스를 제공하며, 고객 비즈니스에 가치를 더하는 일을 합니다\n",
    "  - 기존에 없던 새로운 시스템을 만들어내고, 시스템을 안정적으로 운영해냅니다.\n",
    "  - 디지털금융, 지능형 정부, 스마트시티, 스마트 교통 서비스 등 편리하고 보다 나은 삶을 위한 변화를 이끌어갑니다.\n",
    "  - 국내외 고객에게 DX환경에 적합한 클라우드 인프라 설계/구축/컨설팅/운영 서비스를 제공합니다.\n",
    "  - 국내 및 해외(미국, 유럽, 중국 등) 데이터센터와 클라우드 인프라 기술을 이용하여, 전 세계를 하나로 연결하는 서비스를 제공합니다.\n",
    "\n",
    "- 이런 분이면 더 좋겠어요!\n",
    "  - 새로운 시도를 즐기고, IT를 통해 세상의 변화를 이끌어가고 싶은 분\n",
    "  - 끊임없이 신기술을 익히고 적용하며 성장하고 싶으신 분\n",
    "  - 비즈니스를 이해하고 더 편리한 서비스를 제공하는데 관심이 많으신 분\n",
    "\"\"\"\n",
    "#initial_chat_prompt.format_messages(company=\"LG CNS\", job=\"DX Engineer\", job_requirements=input_job_requirements)\n",
    "\n",
    "# 5. Chain으로 2개를 엮어서 결과값을 출력하기\n",
    "chain = LLMChain(llm=chat, prompt=initial_chat_prompt)\n",
    "chain.run(company=\"LG CNS\", job=\"DX Engineer\", job_requirements=input_job_requirements)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-07-01T19:03:25.021528900Z",
     "start_time": "2023-07-01T19:03:24.017307400Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
